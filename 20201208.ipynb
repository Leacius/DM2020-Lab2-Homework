{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import load\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,input_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define the layers\n",
    "        self.fc1 = nn.Linear(input_len,512) # 128\n",
    "        self.hid1 = nn.Linear(512,256)\n",
    "        self.hid2 = nn.Linear(256+input_len,256)\n",
    "        self.hid3 = nn.Linear(256,64)\n",
    "        self.hid4 = nn.Linear(64+256,128)\n",
    "        #self.hid5 = nn.Linear(128,8)\n",
    "        self.out = nn.Linear(128,8)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        s = F.relu(self.fc1(x))\n",
    "        # s = self.dropout(s)\n",
    "        \n",
    "        s = F.relu(self.hid1(s))\n",
    "        s = self.dropout(s)\n",
    "        \n",
    "        s = torch.cat([x,s],1)\n",
    "        s = F.relu(self.hid2(s))\n",
    "        s1 = self.dropout(s)\n",
    "        \n",
    "        s = F.relu(self.hid3(s1))\n",
    "        # s = self.dropout(s)\n",
    "        \n",
    "        s = torch.cat([s1,s],1)\n",
    "        s = F.relu(self.hid4(s))\n",
    "        s = self.dropout(s)\n",
    "        \n",
    "        #s = F.relu(self.hid5(s))\n",
    "        \n",
    "        s = self.out(s)\n",
    "        \n",
    "        return F.log_softmax(s, dim=1)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(70,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'True label',\n",
    "           ylabel = 'Predicted label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(check,epoch,loss,acc=0):\n",
    "    ax.plot(epoch,loss,'ro-')\n",
    "    if (epoch%check==0):\n",
    "        ax.plot(epoch,acc,'bo-')\n",
    "        ax.text(epoch,acc,f\"{acc}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = load(open('D:/DataMining/HW2_kaggle/clean_data/label.pkl','rb'))\n",
    "df_label = pd.read_csv(\"D:/DataMining/HW2_kaggle/emotion.csv\")\n",
    "onehot = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 249\n",
    "df_data_test = pd.read_csv(\"D:/DataMining/HW2_kaggle/clean_data/evaluation_id.csv\")\n",
    "X_evaluation = torch.from_numpy(np.load(\"D:/DataMining/HW2_kaggle/clean_data/FFT160180/X_evaluation.npy\"))\n",
    "X_evaluation.reshape([len(X_evaluation),1,feature_size]).float()\n",
    "\n",
    "X_train = np.load(\"D:/DataMining/HW2_kaggle/clean_data/FFT160180/X_train.npy\")\n",
    "X_train = torch.from_numpy(X_train).reshape([len(X_train),1,feature_size])\n",
    "y_train = torch.from_numpy(np.load(\"D:/DataMining/HW2_kaggle/clean_data/FFT160180/y_train.npy\")).long()\n",
    "#y_train = torch.nn.functional.one_hot(y_train).reshape([len(y_train),1,8])\n",
    "\n",
    "X_test = np.load(\"D:/DataMining/HW2_kaggle/clean_data/FFT160180/X_test.npy\")\n",
    "X_test = torch.from_numpy(X_test).reshape([len(X_test),1,feature_size])\n",
    "y_test = torch.from_numpy(np.load(\"D:/DataMining/HW2_kaggle/clean_data/FFT160180/y_test.npy\")).long()\n",
    "#y_test = torch.nn.functional.one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 27000\n",
    "epochs = 2000\n",
    "check = 50\n",
    "acc_best = 0\n",
    "\n",
    "LOSS = []\n",
    "Precision = []\n",
    "\n",
    "# train\n",
    "torch_train = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset = torch_train, batch_size = batch, shuffle = True, num_workers = 6)\n",
    "\n",
    "# test\n",
    "torch_test = TensorDataset(X_test, y_test)\n",
    "tset_loader = DataLoader(dataset = torch_test, batch_size = batch, shuffle = True, num_workers = 6)\n",
    "\n",
    "# evaluation\n",
    "torch_val = TensorDataset(X_evaluation, torch.from_numpy(np.array(df_data_test.index)))\n",
    "val_loader = DataLoader(dataset = torch_val, batch_size = batch, shuffle = False, num_workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=249, out_features=512, bias=True)\n",
       "  (hid1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (hid2): Linear(in_features=505, out_features=256, bias=True)\n",
       "  (hid3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (hid4): Linear(in_features=320, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=8, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_len = len(X_train.T)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#device= 'cpu'\n",
    "model = Net(input_len).to(device) # batch\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:1.7955116033554077\n",
      "Training data Accuracy : 386849/1091672 = 0.354\n",
      "epoch:1, loss:1.7762635946273804\n",
      "epoch:2, loss:1.7641451358795166\n",
      "epoch:3, loss:1.7614154815673828\n",
      "epoch:4, loss:1.7535640001296997\n",
      "epoch:5, loss:1.740766167640686\n",
      "epoch:6, loss:1.746897578239441\n",
      "epoch:7, loss:1.732366681098938\n",
      "epoch:8, loss:1.7312082052230835\n",
      "epoch:9, loss:1.7229502201080322\n",
      "epoch:10, loss:1.7214148044586182\n",
      "epoch:11, loss:1.7310534715652466\n",
      "epoch:12, loss:1.731738805770874\n",
      "epoch:13, loss:1.7143592834472656\n",
      "epoch:14, loss:1.7185776233673096\n",
      "epoch:15, loss:1.7160879373550415\n",
      "epoch:16, loss:1.7174314260482788\n",
      "epoch:17, loss:1.7155007123947144\n",
      "epoch:18, loss:1.710903525352478\n",
      "epoch:19, loss:1.7139251232147217\n",
      "epoch:20, loss:1.6920969486236572\n",
      "epoch:21, loss:1.7089424133300781\n",
      "epoch:22, loss:1.703829288482666\n",
      "epoch:23, loss:1.7055175304412842\n",
      "epoch:24, loss:1.7104895114898682\n",
      "epoch:25, loss:1.6997178792953491\n",
      "epoch:26, loss:1.711100459098816\n",
      "epoch:27, loss:1.6881545782089233\n",
      "epoch:28, loss:1.6874427795410156\n",
      "epoch:29, loss:1.6986149549484253\n",
      "epoch:30, loss:1.6966750621795654\n",
      "epoch:31, loss:1.694430947303772\n",
      "epoch:32, loss:1.6990435123443604\n",
      "epoch:33, loss:1.6928637027740479\n",
      "epoch:34, loss:1.6903725862503052\n",
      "epoch:35, loss:1.6802231073379517\n",
      "epoch:36, loss:1.694274663925171\n",
      "epoch:37, loss:1.690660834312439\n",
      "epoch:38, loss:1.699893832206726\n",
      "epoch:39, loss:1.6973367929458618\n",
      "epoch:40, loss:1.6920944452285767\n",
      "epoch:41, loss:1.6961627006530762\n",
      "epoch:42, loss:1.6978068351745605\n",
      "epoch:43, loss:1.687504529953003\n",
      "epoch:44, loss:1.6846709251403809\n",
      "epoch:45, loss:1.692038893699646\n",
      "epoch:46, loss:1.6988005638122559\n",
      "epoch:47, loss:1.693565845489502\n",
      "epoch:48, loss:1.675369381904602\n",
      "epoch:49, loss:1.684506893157959\n",
      "epoch:50, loss:1.6951225996017456\n",
      "Training data Accuracy : 422111/1091672 = 0.387\n",
      "epoch:51, loss:1.6822539567947388\n",
      "epoch:52, loss:1.6837350130081177\n",
      "epoch:53, loss:1.6898339986801147\n",
      "epoch:54, loss:1.6871086359024048\n",
      "epoch:55, loss:1.6877431869506836\n",
      "epoch:56, loss:1.6867492198944092\n",
      "epoch:57, loss:1.6874544620513916\n",
      "epoch:58, loss:1.67387855052948\n",
      "epoch:59, loss:1.6856545209884644\n",
      "epoch:60, loss:1.674660086631775\n",
      "epoch:61, loss:1.6871120929718018\n",
      "epoch:62, loss:1.6727739572525024\n",
      "epoch:63, loss:1.6921926736831665\n",
      "epoch:64, loss:1.664899468421936\n",
      "epoch:65, loss:1.6698378324508667\n",
      "epoch:66, loss:1.6730455160140991\n",
      "epoch:67, loss:1.6719566583633423\n",
      "epoch:68, loss:1.6733876466751099\n",
      "epoch:69, loss:1.6816816329956055\n",
      "epoch:70, loss:1.6856658458709717\n",
      "epoch:71, loss:1.6617757081985474\n",
      "epoch:72, loss:1.670933723449707\n",
      "epoch:73, loss:1.6756598949432373\n",
      "epoch:74, loss:1.664450764656067\n",
      "epoch:75, loss:1.6739044189453125\n",
      "epoch:76, loss:1.6728461980819702\n",
      "epoch:77, loss:1.6730599403381348\n",
      "epoch:78, loss:1.6768991947174072\n",
      "epoch:79, loss:1.6707619428634644\n",
      "epoch:80, loss:1.67792809009552\n",
      "epoch:81, loss:1.6817831993103027\n",
      "epoch:82, loss:1.6671899557113647\n",
      "epoch:83, loss:1.6747781038284302\n",
      "epoch:84, loss:1.6731293201446533\n",
      "epoch:85, loss:1.6766269207000732\n",
      "epoch:86, loss:1.6781277656555176\n",
      "epoch:87, loss:1.6639351844787598\n",
      "epoch:88, loss:1.6766990423202515\n",
      "epoch:89, loss:1.684607982635498\n",
      "epoch:90, loss:1.6738392114639282\n",
      "epoch:91, loss:1.664233684539795\n",
      "epoch:92, loss:1.6785707473754883\n",
      "epoch:93, loss:1.6726951599121094\n",
      "epoch:94, loss:1.679572343826294\n",
      "epoch:95, loss:1.6763885021209717\n",
      "epoch:96, loss:1.6780112981796265\n",
      "epoch:97, loss:1.6642059087753296\n",
      "epoch:98, loss:1.6565433740615845\n",
      "epoch:99, loss:1.6880134344100952\n",
      "epoch:100, loss:1.6723244190216064\n",
      "Training data Accuracy : 426319/1091672 = 0.391\n",
      "epoch:101, loss:1.6720072031021118\n",
      "epoch:102, loss:1.680933952331543\n",
      "epoch:103, loss:1.6699628829956055\n",
      "epoch:104, loss:1.676801323890686\n",
      "epoch:105, loss:1.680497407913208\n",
      "epoch:106, loss:1.6668540239334106\n",
      "epoch:107, loss:1.6851142644882202\n",
      "epoch:108, loss:1.6595685482025146\n",
      "epoch:109, loss:1.6676807403564453\n",
      "epoch:110, loss:1.6829479932785034\n",
      "epoch:111, loss:1.6575876474380493\n",
      "epoch:112, loss:1.672697901725769\n",
      "epoch:113, loss:1.6759836673736572\n",
      "epoch:114, loss:1.6710669994354248\n",
      "epoch:115, loss:1.6668781042099\n",
      "epoch:116, loss:1.6601064205169678\n",
      "epoch:117, loss:1.6717572212219238\n",
      "epoch:118, loss:1.6798031330108643\n",
      "epoch:119, loss:1.664671540260315\n",
      "epoch:120, loss:1.6748385429382324\n",
      "epoch:121, loss:1.679269552230835\n",
      "epoch:122, loss:1.6611405611038208\n",
      "epoch:123, loss:1.6605989933013916\n",
      "epoch:124, loss:1.668257713317871\n",
      "epoch:125, loss:1.6683895587921143\n",
      "epoch:126, loss:1.6629328727722168\n",
      "epoch:127, loss:1.6701058149337769\n",
      "epoch:128, loss:1.6634743213653564\n",
      "epoch:129, loss:1.664957880973816\n",
      "epoch:130, loss:1.6739836931228638\n",
      "epoch:131, loss:1.6456574201583862\n",
      "epoch:132, loss:1.673278570175171\n",
      "epoch:133, loss:1.6673918962478638\n",
      "epoch:134, loss:1.6701833009719849\n",
      "epoch:135, loss:1.6681549549102783\n",
      "epoch:136, loss:1.6766022443771362\n",
      "epoch:137, loss:1.6674362421035767\n",
      "epoch:138, loss:1.6709275245666504\n",
      "epoch:139, loss:1.677219033241272\n",
      "epoch:140, loss:1.670061707496643\n",
      "epoch:141, loss:1.649152398109436\n",
      "epoch:142, loss:1.6754326820373535\n",
      "epoch:143, loss:1.6582167148590088\n",
      "epoch:144, loss:1.6610511541366577\n",
      "epoch:145, loss:1.681599736213684\n",
      "epoch:146, loss:1.6598930358886719\n",
      "epoch:147, loss:1.648601770401001\n",
      "epoch:148, loss:1.6704500913619995\n",
      "epoch:149, loss:1.673532485961914\n",
      "epoch:150, loss:1.6570239067077637\n",
      "Training data Accuracy : 429616/1091672 = 0.394\n",
      "epoch:151, loss:1.6478899717330933\n",
      "epoch:152, loss:1.657189130783081\n",
      "epoch:153, loss:1.6538134813308716\n",
      "epoch:154, loss:1.6568037271499634\n",
      "epoch:155, loss:1.6706278324127197\n",
      "epoch:156, loss:1.6631450653076172\n",
      "epoch:157, loss:1.6494249105453491\n",
      "epoch:158, loss:1.6473058462142944\n",
      "epoch:159, loss:1.671296238899231\n",
      "epoch:160, loss:1.6544278860092163\n",
      "epoch:161, loss:1.6524075269699097\n",
      "epoch:162, loss:1.6681129932403564\n",
      "epoch:163, loss:1.659211277961731\n",
      "epoch:164, loss:1.6603680849075317\n",
      "epoch:165, loss:1.6618261337280273\n",
      "epoch:166, loss:1.6559433937072754\n",
      "epoch:167, loss:1.6504095792770386\n",
      "epoch:168, loss:1.6540921926498413\n",
      "epoch:169, loss:1.6627708673477173\n",
      "epoch:170, loss:1.6605809926986694\n",
      "epoch:171, loss:1.6585259437561035\n",
      "epoch:172, loss:1.6564944982528687\n",
      "epoch:173, loss:1.6519209146499634\n",
      "epoch:174, loss:1.6597696542739868\n",
      "epoch:175, loss:1.6687860488891602\n",
      "epoch:176, loss:1.667941927909851\n",
      "epoch:177, loss:1.6568398475646973\n",
      "epoch:178, loss:1.6636135578155518\n",
      "epoch:179, loss:1.6593546867370605\n",
      "epoch:180, loss:1.6731433868408203\n",
      "epoch:181, loss:1.665543794631958\n",
      "epoch:182, loss:1.6722115278244019\n",
      "epoch:183, loss:1.6548551321029663\n",
      "epoch:184, loss:1.6674938201904297\n",
      "epoch:185, loss:1.6588433980941772\n",
      "epoch:186, loss:1.6671042442321777\n",
      "epoch:187, loss:1.6612571477890015\n",
      "epoch:188, loss:1.6635099649429321\n",
      "epoch:189, loss:1.6593927145004272\n",
      "epoch:190, loss:1.6622064113616943\n",
      "epoch:191, loss:1.6713958978652954\n",
      "epoch:192, loss:1.6618988513946533\n",
      "epoch:193, loss:1.6513527631759644\n",
      "epoch:194, loss:1.6588826179504395\n",
      "epoch:195, loss:1.6647592782974243\n",
      "epoch:196, loss:1.6699637174606323\n",
      "epoch:197, loss:1.6544734239578247\n",
      "epoch:198, loss:1.6560406684875488\n",
      "epoch:199, loss:1.6679185628890991\n",
      "epoch:200, loss:1.6461291313171387\n",
      "Training data Accuracy : 432346/1091672 = 0.396\n",
      "epoch:201, loss:1.6562812328338623\n",
      "epoch:202, loss:1.6577517986297607\n",
      "epoch:203, loss:1.6681768894195557\n",
      "epoch:204, loss:1.659203290939331\n",
      "epoch:205, loss:1.6655133962631226\n",
      "epoch:206, loss:1.651511788368225\n",
      "epoch:207, loss:1.6461601257324219\n",
      "epoch:208, loss:1.6533464193344116\n",
      "epoch:209, loss:1.6544511318206787\n",
      "epoch:210, loss:1.6618221998214722\n",
      "epoch:211, loss:1.6624095439910889\n",
      "epoch:212, loss:1.6553624868392944\n",
      "epoch:213, loss:1.6631250381469727\n",
      "epoch:214, loss:1.6541253328323364\n",
      "epoch:215, loss:1.648337960243225\n",
      "epoch:216, loss:1.6508901119232178\n",
      "epoch:217, loss:1.6482880115509033\n",
      "epoch:218, loss:1.6605358123779297\n",
      "epoch:219, loss:1.6576157808303833\n",
      "epoch:220, loss:1.6612591743469238\n",
      "epoch:221, loss:1.6523536443710327\n",
      "epoch:222, loss:1.6600297689437866\n",
      "epoch:223, loss:1.650985836982727\n",
      "epoch:224, loss:1.6545923948287964\n",
      "epoch:225, loss:1.644939661026001\n",
      "epoch:226, loss:1.6579499244689941\n",
      "epoch:227, loss:1.6429486274719238\n",
      "epoch:228, loss:1.6540387868881226\n",
      "epoch:229, loss:1.6716316938400269\n",
      "epoch:230, loss:1.645759105682373\n",
      "epoch:231, loss:1.6552369594573975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:232, loss:1.6535789966583252\n",
      "epoch:233, loss:1.6570338010787964\n",
      "epoch:234, loss:1.6481187343597412\n",
      "epoch:235, loss:1.6551539897918701\n",
      "epoch:236, loss:1.6623297929763794\n",
      "epoch:237, loss:1.6479686498641968\n",
      "epoch:238, loss:1.650057315826416\n",
      "epoch:239, loss:1.646229863166809\n",
      "epoch:240, loss:1.6547937393188477\n",
      "epoch:241, loss:1.6539320945739746\n",
      "epoch:242, loss:1.646659016609192\n",
      "epoch:243, loss:1.655827522277832\n",
      "epoch:244, loss:1.6614887714385986\n",
      "epoch:245, loss:1.6642041206359863\n",
      "epoch:246, loss:1.6404539346694946\n",
      "epoch:247, loss:1.6587566137313843\n",
      "epoch:248, loss:1.663342833518982\n",
      "epoch:249, loss:1.6557680368423462\n",
      "epoch:250, loss:1.6528246402740479\n",
      "Training data Accuracy : 435776/1091672 = 0.399\n",
      "epoch:251, loss:1.6427034139633179\n",
      "epoch:252, loss:1.6506823301315308\n",
      "epoch:253, loss:1.6471740007400513\n",
      "epoch:254, loss:1.6322718858718872\n",
      "epoch:255, loss:1.6502721309661865\n",
      "epoch:256, loss:1.6598193645477295\n",
      "epoch:257, loss:1.653224229812622\n",
      "epoch:258, loss:1.6538628339767456\n",
      "epoch:259, loss:1.653420329093933\n",
      "epoch:260, loss:1.6514384746551514\n",
      "epoch:261, loss:1.6550416946411133\n",
      "epoch:262, loss:1.6371103525161743\n",
      "epoch:263, loss:1.6507880687713623\n",
      "epoch:264, loss:1.6576378345489502\n",
      "epoch:265, loss:1.6485897302627563\n",
      "epoch:266, loss:1.6537833213806152\n",
      "epoch:267, loss:1.6452993154525757\n",
      "epoch:268, loss:1.6434705257415771\n",
      "epoch:269, loss:1.6432775259017944\n",
      "epoch:270, loss:1.6383198499679565\n",
      "epoch:271, loss:1.658132553100586\n",
      "epoch:272, loss:1.651638150215149\n",
      "epoch:273, loss:1.6652806997299194\n",
      "epoch:274, loss:1.6421929597854614\n",
      "epoch:275, loss:1.6556061506271362\n",
      "epoch:276, loss:1.6497548818588257\n",
      "epoch:277, loss:1.663380742073059\n",
      "epoch:278, loss:1.6443252563476562\n",
      "epoch:279, loss:1.6491496562957764\n",
      "epoch:280, loss:1.6482999324798584\n",
      "epoch:281, loss:1.6548534631729126\n",
      "epoch:282, loss:1.633191466331482\n",
      "epoch:283, loss:1.6560742855072021\n",
      "epoch:284, loss:1.6436247825622559\n",
      "epoch:285, loss:1.6300041675567627\n",
      "epoch:286, loss:1.6436923742294312\n",
      "epoch:287, loss:1.6504225730895996\n",
      "epoch:288, loss:1.6518280506134033\n",
      "epoch:289, loss:1.652359962463379\n",
      "epoch:290, loss:1.6523542404174805\n",
      "epoch:291, loss:1.6482813358306885\n",
      "epoch:292, loss:1.6488533020019531\n",
      "epoch:293, loss:1.6451632976531982\n",
      "epoch:294, loss:1.6355518102645874\n",
      "epoch:295, loss:1.6477980613708496\n",
      "epoch:296, loss:1.6547995805740356\n",
      "epoch:297, loss:1.6429954767227173\n",
      "epoch:298, loss:1.6468504667282104\n",
      "epoch:299, loss:1.6402440071105957\n",
      "epoch:300, loss:1.6557085514068604\n",
      "Training data Accuracy : 437256/1091672 = 0.401\n",
      "epoch:301, loss:1.659735918045044\n",
      "epoch:302, loss:1.6530275344848633\n",
      "epoch:303, loss:1.631526231765747\n",
      "epoch:304, loss:1.6531885862350464\n",
      "epoch:305, loss:1.640768051147461\n",
      "epoch:306, loss:1.6474456787109375\n",
      "epoch:307, loss:1.628976821899414\n",
      "epoch:308, loss:1.6483820676803589\n",
      "epoch:309, loss:1.6508902311325073\n",
      "epoch:310, loss:1.640832781791687\n",
      "epoch:311, loss:1.6463762521743774\n",
      "epoch:312, loss:1.638521432876587\n",
      "epoch:313, loss:1.640419840812683\n",
      "epoch:314, loss:1.6481754779815674\n",
      "epoch:315, loss:1.6424534320831299\n",
      "epoch:316, loss:1.6462616920471191\n",
      "epoch:317, loss:1.6440529823303223\n",
      "epoch:318, loss:1.6429321765899658\n",
      "epoch:319, loss:1.6380008459091187\n",
      "epoch:320, loss:1.6389127969741821\n",
      "epoch:321, loss:1.640594244003296\n",
      "epoch:322, loss:1.6565289497375488\n",
      "epoch:323, loss:1.6567974090576172\n",
      "epoch:324, loss:1.6476409435272217\n",
      "epoch:325, loss:1.645514965057373\n",
      "epoch:326, loss:1.6510651111602783\n",
      "epoch:327, loss:1.6390424966812134\n",
      "epoch:328, loss:1.6311243772506714\n",
      "epoch:329, loss:1.6416507959365845\n",
      "epoch:330, loss:1.637922763824463\n",
      "epoch:331, loss:1.6407195329666138\n",
      "epoch:332, loss:1.6465928554534912\n",
      "epoch:333, loss:1.638475775718689\n",
      "epoch:334, loss:1.6561633348464966\n",
      "epoch:335, loss:1.645777940750122\n",
      "epoch:336, loss:1.6507962942123413\n",
      "epoch:337, loss:1.6432546377182007\n",
      "epoch:338, loss:1.6426900625228882\n",
      "epoch:339, loss:1.6544133424758911\n",
      "epoch:340, loss:1.651253581047058\n",
      "epoch:341, loss:1.6425002813339233\n",
      "epoch:342, loss:1.642331600189209\n",
      "epoch:343, loss:1.6530272960662842\n",
      "epoch:344, loss:1.6463671922683716\n",
      "epoch:345, loss:1.6325342655181885\n",
      "epoch:346, loss:1.626957654953003\n",
      "epoch:347, loss:1.643221139907837\n",
      "epoch:348, loss:1.6435322761535645\n",
      "epoch:349, loss:1.6461145877838135\n",
      "epoch:350, loss:1.645564079284668\n",
      "Training data Accuracy : 439544/1091672 = 0.403\n",
      "epoch:351, loss:1.6395481824874878\n",
      "epoch:352, loss:1.647334098815918\n",
      "epoch:353, loss:1.6434651613235474\n",
      "epoch:354, loss:1.6307069063186646\n",
      "epoch:355, loss:1.6452782154083252\n",
      "epoch:356, loss:1.6312644481658936\n",
      "epoch:357, loss:1.6327241659164429\n",
      "epoch:358, loss:1.6459522247314453\n",
      "epoch:359, loss:1.647722601890564\n",
      "epoch:360, loss:1.6326184272766113\n",
      "epoch:361, loss:1.649175763130188\n",
      "epoch:362, loss:1.634704828262329\n",
      "epoch:363, loss:1.6498901844024658\n",
      "epoch:364, loss:1.653770089149475\n",
      "epoch:365, loss:1.6346083879470825\n",
      "epoch:366, loss:1.6323072910308838\n",
      "epoch:367, loss:1.6375850439071655\n",
      "epoch:368, loss:1.6462966203689575\n",
      "epoch:369, loss:1.646026849746704\n",
      "epoch:370, loss:1.6322089433670044\n",
      "epoch:371, loss:1.6263293027877808\n",
      "epoch:372, loss:1.6312932968139648\n",
      "epoch:373, loss:1.651091456413269\n",
      "epoch:374, loss:1.6364045143127441\n",
      "epoch:375, loss:1.6563514471054077\n",
      "epoch:376, loss:1.638243556022644\n",
      "epoch:377, loss:1.6411473751068115\n",
      "epoch:378, loss:1.6355947256088257\n",
      "epoch:379, loss:1.6529545783996582\n",
      "epoch:380, loss:1.6351723670959473\n",
      "epoch:381, loss:1.634328842163086\n",
      "epoch:382, loss:1.6486326456069946\n",
      "epoch:383, loss:1.6500071287155151\n",
      "epoch:384, loss:1.643280267715454\n",
      "epoch:385, loss:1.6280378103256226\n",
      "epoch:386, loss:1.6487334966659546\n",
      "epoch:387, loss:1.6425262689590454\n",
      "epoch:388, loss:1.6454747915267944\n",
      "epoch:389, loss:1.6450526714324951\n",
      "epoch:390, loss:1.6452593803405762\n",
      "epoch:391, loss:1.635932445526123\n",
      "epoch:392, loss:1.6332788467407227\n",
      "epoch:393, loss:1.6231725215911865\n",
      "epoch:394, loss:1.6447376012802124\n",
      "epoch:395, loss:1.6391974687576294\n",
      "epoch:396, loss:1.6316300630569458\n",
      "epoch:397, loss:1.6366006135940552\n",
      "epoch:398, loss:1.6418026685714722\n",
      "epoch:399, loss:1.6374846696853638\n",
      "epoch:400, loss:1.6552422046661377\n",
      "Training data Accuracy : 440827/1091672 = 0.404\n",
      "epoch:401, loss:1.6447874307632446\n",
      "epoch:402, loss:1.636291742324829\n",
      "epoch:403, loss:1.6450592279434204\n",
      "epoch:404, loss:1.642329454421997\n",
      "epoch:405, loss:1.6489839553833008\n",
      "epoch:406, loss:1.6439663171768188\n",
      "epoch:407, loss:1.6470667123794556\n",
      "epoch:408, loss:1.6323572397232056\n",
      "epoch:409, loss:1.6279106140136719\n",
      "epoch:410, loss:1.6277841329574585\n",
      "epoch:411, loss:1.6483769416809082\n",
      "epoch:412, loss:1.6314482688903809\n",
      "epoch:413, loss:1.6466546058654785\n",
      "epoch:414, loss:1.639371633529663\n",
      "epoch:415, loss:1.639280915260315\n",
      "epoch:416, loss:1.645695686340332\n",
      "epoch:417, loss:1.639599084854126\n",
      "epoch:418, loss:1.63922119140625\n",
      "epoch:419, loss:1.6445486545562744\n",
      "epoch:420, loss:1.6378324031829834\n",
      "epoch:421, loss:1.6403510570526123\n",
      "epoch:422, loss:1.6331183910369873\n",
      "epoch:423, loss:1.6539143323898315\n",
      "epoch:424, loss:1.6419867277145386\n",
      "epoch:425, loss:1.6452834606170654\n",
      "epoch:426, loss:1.6321330070495605\n",
      "epoch:427, loss:1.646183967590332\n",
      "epoch:428, loss:1.6314445734024048\n",
      "epoch:429, loss:1.6525557041168213\n",
      "epoch:430, loss:1.6242668628692627\n",
      "epoch:431, loss:1.6434162855148315\n",
      "epoch:432, loss:1.6388970613479614\n",
      "epoch:433, loss:1.6493608951568604\n",
      "epoch:434, loss:1.6368211507797241\n",
      "epoch:435, loss:1.6397043466567993\n",
      "epoch:436, loss:1.6451987028121948\n",
      "epoch:437, loss:1.6336146593093872\n",
      "epoch:438, loss:1.6359601020812988\n",
      "epoch:439, loss:1.6331247091293335\n",
      "epoch:440, loss:1.649050235748291\n",
      "epoch:441, loss:1.6328362226486206\n",
      "epoch:442, loss:1.639398455619812\n",
      "epoch:443, loss:1.643078088760376\n",
      "epoch:444, loss:1.631364345550537\n",
      "epoch:445, loss:1.6300592422485352\n",
      "epoch:446, loss:1.636387586593628\n",
      "epoch:447, loss:1.6230003833770752\n",
      "epoch:448, loss:1.6334381103515625\n",
      "epoch:449, loss:1.6391236782073975\n",
      "epoch:450, loss:1.6341344118118286\n",
      "Training data Accuracy : 442666/1091672 = 0.405\n",
      "epoch:451, loss:1.635714054107666\n",
      "epoch:452, loss:1.6360920667648315\n",
      "epoch:453, loss:1.6397068500518799\n",
      "epoch:454, loss:1.6376770734786987\n",
      "epoch:455, loss:1.6313642263412476\n",
      "epoch:456, loss:1.6332849264144897\n",
      "epoch:457, loss:1.6386910676956177\n",
      "epoch:458, loss:1.6273505687713623\n",
      "epoch:459, loss:1.6293692588806152\n",
      "epoch:460, loss:1.6283979415893555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:461, loss:1.635895013809204\n",
      "epoch:462, loss:1.6422109603881836\n",
      "epoch:463, loss:1.642194151878357\n",
      "epoch:464, loss:1.6261825561523438\n",
      "epoch:465, loss:1.6289551258087158\n",
      "epoch:466, loss:1.6335780620574951\n",
      "epoch:467, loss:1.6255769729614258\n",
      "epoch:468, loss:1.6260888576507568\n",
      "epoch:469, loss:1.6432907581329346\n",
      "epoch:470, loss:1.640458345413208\n",
      "epoch:471, loss:1.6421706676483154\n",
      "epoch:472, loss:1.640386700630188\n",
      "epoch:473, loss:1.6263920068740845\n",
      "epoch:474, loss:1.6439765691757202\n",
      "epoch:475, loss:1.634658694267273\n",
      "epoch:476, loss:1.642583966255188\n",
      "epoch:477, loss:1.6383020877838135\n",
      "epoch:478, loss:1.6438062191009521\n",
      "epoch:479, loss:1.644758701324463\n",
      "epoch:480, loss:1.6423085927963257\n",
      "epoch:481, loss:1.6327259540557861\n",
      "epoch:482, loss:1.6357330083847046\n",
      "epoch:483, loss:1.6342028379440308\n",
      "epoch:484, loss:1.6365783214569092\n",
      "epoch:485, loss:1.6437807083129883\n",
      "epoch:486, loss:1.6285642385482788\n",
      "epoch:487, loss:1.6304683685302734\n",
      "epoch:488, loss:1.64322030544281\n",
      "epoch:489, loss:1.6373182535171509\n",
      "epoch:490, loss:1.647879958152771\n",
      "epoch:491, loss:1.6536839008331299\n",
      "epoch:492, loss:1.6248286962509155\n",
      "epoch:493, loss:1.6442548036575317\n",
      "epoch:494, loss:1.6217702627182007\n",
      "epoch:495, loss:1.6409293413162231\n",
      "epoch:496, loss:1.6339523792266846\n",
      "epoch:497, loss:1.6317386627197266\n",
      "epoch:498, loss:1.637474775314331\n",
      "epoch:499, loss:1.6389329433441162\n",
      "epoch:500, loss:1.6281278133392334\n",
      "Training data Accuracy : 445039/1091672 = 0.408\n",
      "epoch:501, loss:1.6290794610977173\n",
      "epoch:502, loss:1.6293632984161377\n",
      "epoch:503, loss:1.6378263235092163\n",
      "epoch:504, loss:1.6231439113616943\n",
      "epoch:505, loss:1.631076693534851\n",
      "epoch:506, loss:1.6273057460784912\n",
      "epoch:507, loss:1.6220569610595703\n",
      "epoch:508, loss:1.6239427328109741\n",
      "epoch:509, loss:1.6349737644195557\n",
      "epoch:510, loss:1.626853108406067\n",
      "epoch:511, loss:1.6476048231124878\n",
      "epoch:512, loss:1.653674840927124\n",
      "epoch:513, loss:1.627445101737976\n",
      "epoch:514, loss:1.6218377351760864\n",
      "epoch:515, loss:1.62548828125\n",
      "epoch:516, loss:1.634060025215149\n",
      "epoch:517, loss:1.629724383354187\n",
      "epoch:518, loss:1.6350992918014526\n",
      "epoch:519, loss:1.6347321271896362\n",
      "epoch:520, loss:1.6450235843658447\n",
      "epoch:521, loss:1.6379749774932861\n",
      "epoch:522, loss:1.6343580484390259\n",
      "epoch:523, loss:1.6344783306121826\n",
      "epoch:524, loss:1.6460150480270386\n",
      "epoch:525, loss:1.6394013166427612\n",
      "epoch:526, loss:1.6188315153121948\n",
      "epoch:527, loss:1.6376718282699585\n",
      "epoch:528, loss:1.6370048522949219\n",
      "epoch:529, loss:1.6364161968231201\n",
      "epoch:530, loss:1.638590693473816\n",
      "epoch:531, loss:1.6388190984725952\n",
      "epoch:532, loss:1.6314729452133179\n",
      "epoch:533, loss:1.6364446878433228\n",
      "epoch:534, loss:1.6341543197631836\n",
      "epoch:535, loss:1.6356281042099\n",
      "epoch:536, loss:1.6323285102844238\n",
      "epoch:537, loss:1.6276404857635498\n",
      "epoch:538, loss:1.6358357667922974\n",
      "epoch:539, loss:1.6363179683685303\n",
      "epoch:540, loss:1.6483509540557861\n",
      "epoch:541, loss:1.6216479539871216\n",
      "epoch:542, loss:1.6303740739822388\n",
      "epoch:543, loss:1.6406124830245972\n",
      "epoch:544, loss:1.6328095197677612\n",
      "epoch:545, loss:1.6489983797073364\n",
      "epoch:546, loss:1.6380219459533691\n",
      "epoch:547, loss:1.6539123058319092\n",
      "epoch:548, loss:1.6350412368774414\n",
      "epoch:549, loss:1.6215713024139404\n",
      "epoch:550, loss:1.631632685661316\n",
      "Training data Accuracy : 445589/1091672 = 0.408\n",
      "epoch:551, loss:1.63185453414917\n",
      "epoch:552, loss:1.628310203552246\n",
      "epoch:553, loss:1.6326839923858643\n",
      "epoch:554, loss:1.628878116607666\n",
      "epoch:555, loss:1.6196856498718262\n",
      "epoch:556, loss:1.6269241571426392\n",
      "epoch:557, loss:1.6367648839950562\n",
      "epoch:558, loss:1.622081995010376\n",
      "epoch:559, loss:1.6308165788650513\n",
      "epoch:560, loss:1.6402913331985474\n",
      "epoch:561, loss:1.638814091682434\n",
      "epoch:562, loss:1.6389847993850708\n",
      "epoch:563, loss:1.6322847604751587\n",
      "epoch:564, loss:1.6285146474838257\n",
      "epoch:565, loss:1.6452484130859375\n",
      "epoch:566, loss:1.6247206926345825\n",
      "epoch:567, loss:1.6426419019699097\n",
      "epoch:568, loss:1.6366745233535767\n",
      "epoch:569, loss:1.6448495388031006\n",
      "epoch:570, loss:1.6176307201385498\n",
      "epoch:571, loss:1.6310476064682007\n",
      "epoch:572, loss:1.6241482496261597\n",
      "epoch:573, loss:1.6362698078155518\n",
      "epoch:574, loss:1.6273674964904785\n",
      "epoch:575, loss:1.6132917404174805\n",
      "epoch:576, loss:1.6333659887313843\n",
      "epoch:577, loss:1.6333976984024048\n",
      "epoch:578, loss:1.6245170831680298\n",
      "epoch:579, loss:1.6387954950332642\n",
      "epoch:580, loss:1.6247860193252563\n",
      "epoch:581, loss:1.6325517892837524\n",
      "epoch:582, loss:1.630014181137085\n",
      "epoch:583, loss:1.6514939069747925\n",
      "epoch:584, loss:1.6131527423858643\n",
      "epoch:585, loss:1.6292616128921509\n",
      "epoch:586, loss:1.6380091905593872\n",
      "epoch:587, loss:1.6344630718231201\n",
      "epoch:588, loss:1.6413196325302124\n",
      "epoch:589, loss:1.6355291604995728\n",
      "epoch:590, loss:1.6227277517318726\n",
      "epoch:591, loss:1.6349122524261475\n",
      "epoch:592, loss:1.6385926008224487\n",
      "epoch:593, loss:1.6219377517700195\n",
      "epoch:594, loss:1.6394122838974\n",
      "epoch:595, loss:1.6354007720947266\n",
      "epoch:596, loss:1.6317800283432007\n",
      "epoch:597, loss:1.6257842779159546\n",
      "epoch:598, loss:1.6226476430892944\n",
      "epoch:599, loss:1.627591848373413\n",
      "epoch:600, loss:1.6189768314361572\n",
      "Training data Accuracy : 447048/1091672 = 0.41\n",
      "epoch:601, loss:1.611393928527832\n",
      "epoch:602, loss:1.6410449743270874\n",
      "epoch:603, loss:1.6336567401885986\n",
      "epoch:604, loss:1.6403729915618896\n",
      "epoch:605, loss:1.6228814125061035\n",
      "epoch:606, loss:1.6255189180374146\n",
      "epoch:607, loss:1.615325689315796\n",
      "epoch:608, loss:1.6294032335281372\n",
      "epoch:609, loss:1.6259517669677734\n",
      "epoch:610, loss:1.6474153995513916\n",
      "epoch:611, loss:1.6313140392303467\n",
      "epoch:612, loss:1.6258692741394043\n",
      "epoch:613, loss:1.6261225938796997\n",
      "epoch:614, loss:1.626009225845337\n",
      "epoch:615, loss:1.6306185722351074\n",
      "epoch:616, loss:1.6328576803207397\n",
      "epoch:617, loss:1.613726019859314\n",
      "epoch:618, loss:1.6252529621124268\n",
      "epoch:619, loss:1.626573920249939\n",
      "epoch:620, loss:1.6252176761627197\n",
      "epoch:621, loss:1.6351118087768555\n",
      "epoch:622, loss:1.6205788850784302\n",
      "epoch:623, loss:1.6133164167404175\n",
      "epoch:624, loss:1.6352741718292236\n",
      "epoch:625, loss:1.6205652952194214\n",
      "epoch:626, loss:1.6201528310775757\n",
      "epoch:627, loss:1.6124931573867798\n",
      "epoch:628, loss:1.6491838693618774\n",
      "epoch:629, loss:1.628169298171997\n",
      "epoch:630, loss:1.6224550008773804\n",
      "epoch:631, loss:1.6337333917617798\n",
      "epoch:632, loss:1.647707462310791\n",
      "epoch:633, loss:1.6192744970321655\n",
      "epoch:634, loss:1.6291873455047607\n",
      "epoch:635, loss:1.6254087686538696\n",
      "epoch:636, loss:1.6186864376068115\n",
      "epoch:637, loss:1.61572265625\n",
      "epoch:638, loss:1.6246601343154907\n",
      "epoch:639, loss:1.6174967288970947\n",
      "epoch:640, loss:1.6168712377548218\n",
      "epoch:641, loss:1.6193643808364868\n",
      "epoch:642, loss:1.6309823989868164\n",
      "epoch:643, loss:1.627316951751709\n",
      "epoch:644, loss:1.6296920776367188\n",
      "epoch:645, loss:1.625627040863037\n",
      "epoch:646, loss:1.634079098701477\n",
      "epoch:647, loss:1.6360021829605103\n",
      "epoch:648, loss:1.6418483257293701\n",
      "epoch:649, loss:1.624074101448059\n",
      "epoch:650, loss:1.6348824501037598\n",
      "Training data Accuracy : 448029/1091672 = 0.41\n",
      "epoch:651, loss:1.629163384437561\n",
      "epoch:652, loss:1.6402963399887085\n",
      "epoch:653, loss:1.629515528678894\n",
      "epoch:654, loss:1.6425145864486694\n",
      "epoch:655, loss:1.622506856918335\n",
      "epoch:656, loss:1.631287693977356\n",
      "epoch:657, loss:1.6282663345336914\n",
      "epoch:658, loss:1.6335225105285645\n",
      "epoch:659, loss:1.6335469484329224\n",
      "epoch:660, loss:1.6283432245254517\n",
      "epoch:661, loss:1.628602147102356\n",
      "epoch:662, loss:1.6271121501922607\n",
      "epoch:663, loss:1.6182888746261597\n",
      "epoch:664, loss:1.6270405054092407\n",
      "epoch:665, loss:1.6472200155258179\n",
      "epoch:666, loss:1.619807243347168\n",
      "epoch:667, loss:1.6391949653625488\n",
      "epoch:668, loss:1.6324708461761475\n",
      "epoch:669, loss:1.6239471435546875\n",
      "epoch:670, loss:1.6115292310714722\n",
      "epoch:671, loss:1.6236909627914429\n",
      "epoch:672, loss:1.628894329071045\n",
      "epoch:673, loss:1.6378581523895264\n",
      "epoch:674, loss:1.636847972869873\n",
      "epoch:675, loss:1.628097653388977\n",
      "epoch:676, loss:1.6229830980300903\n",
      "epoch:677, loss:1.6277412176132202\n",
      "epoch:678, loss:1.6378995180130005\n",
      "epoch:679, loss:1.6326653957366943\n",
      "epoch:680, loss:1.6183435916900635\n",
      "epoch:681, loss:1.6177515983581543\n",
      "epoch:682, loss:1.6233000755310059\n",
      "epoch:683, loss:1.6279643774032593\n",
      "epoch:684, loss:1.624398112297058\n",
      "epoch:685, loss:1.6131776571273804\n",
      "epoch:686, loss:1.6284232139587402\n",
      "epoch:687, loss:1.6302648782730103\n",
      "epoch:688, loss:1.6393777132034302\n",
      "epoch:689, loss:1.624538779258728\n",
      "epoch:690, loss:1.6290837526321411\n",
      "epoch:691, loss:1.6295441389083862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:692, loss:1.6288508176803589\n",
      "epoch:693, loss:1.6268373727798462\n",
      "epoch:694, loss:1.6219674348831177\n",
      "epoch:695, loss:1.6209512948989868\n",
      "epoch:696, loss:1.6303110122680664\n",
      "epoch:697, loss:1.6370707750320435\n",
      "epoch:698, loss:1.6157810688018799\n",
      "epoch:699, loss:1.628712773323059\n",
      "epoch:700, loss:1.616902232170105\n",
      "Training data Accuracy : 448617/1091672 = 0.411\n",
      "epoch:701, loss:1.6339391469955444\n",
      "epoch:702, loss:1.6226104497909546\n",
      "epoch:703, loss:1.6294931173324585\n",
      "epoch:704, loss:1.6251786947250366\n",
      "epoch:705, loss:1.6217401027679443\n",
      "epoch:706, loss:1.6212040185928345\n",
      "epoch:707, loss:1.6261584758758545\n",
      "epoch:708, loss:1.6393378973007202\n",
      "epoch:709, loss:1.6253145933151245\n",
      "epoch:710, loss:1.6243596076965332\n",
      "epoch:711, loss:1.6375153064727783\n",
      "epoch:712, loss:1.6373741626739502\n",
      "epoch:713, loss:1.6248342990875244\n",
      "epoch:714, loss:1.6299902200698853\n",
      "epoch:715, loss:1.625343680381775\n",
      "epoch:716, loss:1.6124235391616821\n",
      "epoch:717, loss:1.6231305599212646\n",
      "epoch:718, loss:1.6162887811660767\n",
      "epoch:719, loss:1.6278119087219238\n",
      "epoch:720, loss:1.6322345733642578\n",
      "epoch:721, loss:1.6328390836715698\n",
      "epoch:722, loss:1.619908332824707\n",
      "epoch:723, loss:1.6285152435302734\n",
      "epoch:724, loss:1.6175552606582642\n",
      "epoch:725, loss:1.626147747039795\n",
      "epoch:726, loss:1.6218852996826172\n",
      "epoch:727, loss:1.639273762702942\n",
      "epoch:728, loss:1.6241296529769897\n",
      "epoch:729, loss:1.6265275478363037\n",
      "epoch:730, loss:1.6297121047973633\n",
      "epoch:731, loss:1.6276229619979858\n",
      "epoch:732, loss:1.6297742128372192\n",
      "epoch:733, loss:1.6162371635437012\n",
      "epoch:734, loss:1.63211190700531\n",
      "epoch:735, loss:1.630398154258728\n",
      "epoch:736, loss:1.6406060457229614\n",
      "epoch:737, loss:1.6110173463821411\n",
      "epoch:738, loss:1.6179962158203125\n",
      "epoch:739, loss:1.6220110654830933\n",
      "epoch:740, loss:1.623189091682434\n",
      "epoch:741, loss:1.618829607963562\n",
      "epoch:742, loss:1.6309725046157837\n",
      "epoch:743, loss:1.6157197952270508\n",
      "epoch:744, loss:1.6262811422348022\n",
      "epoch:745, loss:1.625731110572815\n",
      "epoch:746, loss:1.6231671571731567\n",
      "epoch:747, loss:1.6215629577636719\n",
      "epoch:748, loss:1.6213701963424683\n",
      "epoch:749, loss:1.6502857208251953\n",
      "epoch:750, loss:1.612052321434021\n",
      "Training data Accuracy : 448989/1091672 = 0.411\n",
      "epoch:751, loss:1.6294628381729126\n",
      "epoch:752, loss:1.639567255973816\n",
      "epoch:753, loss:1.6120312213897705\n",
      "epoch:754, loss:1.621956467628479\n",
      "epoch:755, loss:1.6265090703964233\n",
      "epoch:756, loss:1.6261942386627197\n",
      "epoch:757, loss:1.633371114730835\n",
      "epoch:758, loss:1.6259194612503052\n",
      "epoch:759, loss:1.6363203525543213\n",
      "epoch:760, loss:1.6223968267440796\n",
      "epoch:761, loss:1.6279194355010986\n",
      "epoch:762, loss:1.6261826753616333\n",
      "epoch:763, loss:1.6182034015655518\n",
      "epoch:764, loss:1.6144795417785645\n",
      "epoch:765, loss:1.6144875288009644\n",
      "epoch:766, loss:1.6201858520507812\n",
      "epoch:767, loss:1.6287872791290283\n",
      "epoch:768, loss:1.622546911239624\n",
      "epoch:769, loss:1.63334059715271\n",
      "epoch:770, loss:1.62313973903656\n",
      "epoch:771, loss:1.6219831705093384\n",
      "epoch:772, loss:1.6243984699249268\n",
      "epoch:773, loss:1.607685923576355\n",
      "epoch:774, loss:1.6306774616241455\n",
      "epoch:775, loss:1.6285150051116943\n",
      "epoch:776, loss:1.6201280355453491\n",
      "epoch:777, loss:1.6171447038650513\n",
      "epoch:778, loss:1.6254183053970337\n",
      "epoch:779, loss:1.619966745376587\n",
      "epoch:780, loss:1.620076298713684\n",
      "epoch:781, loss:1.610386848449707\n",
      "epoch:782, loss:1.6219555139541626\n",
      "epoch:783, loss:1.6275798082351685\n",
      "epoch:784, loss:1.625144124031067\n",
      "epoch:785, loss:1.6087207794189453\n",
      "epoch:786, loss:1.6211670637130737\n",
      "epoch:787, loss:1.625966191291809\n",
      "epoch:788, loss:1.6262632608413696\n",
      "epoch:789, loss:1.6251322031021118\n",
      "epoch:790, loss:1.630242943763733\n",
      "epoch:791, loss:1.608136773109436\n",
      "epoch:792, loss:1.6062856912612915\n",
      "epoch:793, loss:1.6289496421813965\n",
      "epoch:794, loss:1.6311689615249634\n",
      "epoch:795, loss:1.616654396057129\n",
      "epoch:796, loss:1.6196638345718384\n",
      "epoch:797, loss:1.6395223140716553\n",
      "epoch:798, loss:1.6255518198013306\n",
      "epoch:799, loss:1.620470404624939\n",
      "epoch:800, loss:1.619041919708252\n",
      "Training data Accuracy : 450747/1091672 = 0.413\n",
      "epoch:801, loss:1.626412272453308\n",
      "epoch:802, loss:1.6346921920776367\n",
      "epoch:803, loss:1.6161699295043945\n",
      "epoch:804, loss:1.6244243383407593\n",
      "epoch:805, loss:1.6225107908248901\n",
      "epoch:806, loss:1.6157171726226807\n",
      "epoch:807, loss:1.6234617233276367\n",
      "epoch:808, loss:1.618403673171997\n",
      "epoch:809, loss:1.6312832832336426\n",
      "epoch:810, loss:1.6312644481658936\n",
      "epoch:811, loss:1.6357529163360596\n",
      "epoch:812, loss:1.6373733282089233\n",
      "epoch:813, loss:1.6323109865188599\n",
      "epoch:814, loss:1.6146297454833984\n",
      "epoch:815, loss:1.6350983381271362\n",
      "epoch:816, loss:1.6288679838180542\n",
      "epoch:817, loss:1.6265809535980225\n",
      "epoch:818, loss:1.6317940950393677\n",
      "epoch:819, loss:1.6339777708053589\n",
      "epoch:820, loss:1.6185028553009033\n",
      "epoch:821, loss:1.63390052318573\n",
      "epoch:822, loss:1.6206600666046143\n",
      "epoch:823, loss:1.622761845588684\n",
      "epoch:824, loss:1.614892840385437\n",
      "epoch:825, loss:1.6127636432647705\n",
      "epoch:826, loss:1.627577781677246\n",
      "epoch:827, loss:1.6230018138885498\n",
      "epoch:828, loss:1.6180176734924316\n",
      "epoch:829, loss:1.6318902969360352\n",
      "epoch:830, loss:1.6134469509124756\n",
      "epoch:831, loss:1.6182605028152466\n",
      "epoch:832, loss:1.615210771560669\n",
      "epoch:833, loss:1.624538779258728\n",
      "epoch:834, loss:1.6418335437774658\n",
      "epoch:835, loss:1.6216778755187988\n",
      "epoch:836, loss:1.6118639707565308\n",
      "epoch:837, loss:1.624260663986206\n",
      "epoch:838, loss:1.614300012588501\n",
      "epoch:839, loss:1.620059609413147\n",
      "epoch:840, loss:1.6308132410049438\n",
      "epoch:841, loss:1.622761607170105\n",
      "epoch:842, loss:1.6202510595321655\n",
      "epoch:843, loss:1.6307674646377563\n",
      "epoch:844, loss:1.6311330795288086\n",
      "epoch:845, loss:1.6171157360076904\n",
      "epoch:846, loss:1.622393250465393\n",
      "epoch:847, loss:1.6080979108810425\n",
      "epoch:848, loss:1.6233248710632324\n",
      "epoch:849, loss:1.6281551122665405\n",
      "epoch:850, loss:1.619929552078247\n",
      "Training data Accuracy : 451506/1091672 = 0.414\n",
      "epoch:851, loss:1.6188127994537354\n",
      "epoch:852, loss:1.6122076511383057\n",
      "epoch:853, loss:1.6154118776321411\n",
      "epoch:854, loss:1.6242460012435913\n",
      "epoch:855, loss:1.6155755519866943\n",
      "epoch:856, loss:1.6206148862838745\n",
      "epoch:857, loss:1.6195712089538574\n",
      "epoch:858, loss:1.6115118265151978\n",
      "epoch:859, loss:1.6177349090576172\n",
      "epoch:860, loss:1.6218405961990356\n",
      "epoch:861, loss:1.6087557077407837\n",
      "epoch:862, loss:1.6148972511291504\n",
      "epoch:863, loss:1.612182378768921\n",
      "epoch:864, loss:1.6262493133544922\n",
      "epoch:865, loss:1.6272212266921997\n",
      "epoch:866, loss:1.6083035469055176\n",
      "epoch:867, loss:1.6165562868118286\n",
      "epoch:868, loss:1.618406057357788\n",
      "epoch:869, loss:1.620495319366455\n",
      "epoch:870, loss:1.6334885358810425\n",
      "epoch:871, loss:1.6240763664245605\n",
      "epoch:872, loss:1.6320650577545166\n",
      "epoch:873, loss:1.6301041841506958\n",
      "epoch:874, loss:1.6169272661209106\n",
      "epoch:875, loss:1.6155271530151367\n",
      "epoch:876, loss:1.6296321153640747\n",
      "epoch:877, loss:1.613674283027649\n",
      "epoch:878, loss:1.6243181228637695\n",
      "epoch:879, loss:1.6145037412643433\n",
      "epoch:880, loss:1.634157419204712\n",
      "epoch:881, loss:1.630968689918518\n",
      "epoch:882, loss:1.6180487871170044\n",
      "epoch:883, loss:1.6296495199203491\n",
      "epoch:884, loss:1.6106997728347778\n",
      "epoch:885, loss:1.6133637428283691\n",
      "epoch:886, loss:1.619651198387146\n",
      "epoch:887, loss:1.6156423091888428\n",
      "epoch:888, loss:1.6273795366287231\n",
      "epoch:889, loss:1.6130608320236206\n",
      "epoch:890, loss:1.6165509223937988\n",
      "epoch:891, loss:1.6211605072021484\n",
      "epoch:892, loss:1.6359974145889282\n",
      "epoch:893, loss:1.6079176664352417\n",
      "epoch:894, loss:1.6270545721054077\n",
      "epoch:895, loss:1.621041178703308\n",
      "epoch:896, loss:1.6251211166381836\n",
      "epoch:897, loss:1.61837637424469\n",
      "epoch:898, loss:1.6308270692825317\n",
      "epoch:899, loss:1.6279221773147583\n",
      "epoch:900, loss:1.619689702987671\n",
      "Training data Accuracy : 451841/1091672 = 0.414\n",
      "epoch:901, loss:1.6199849843978882\n",
      "epoch:902, loss:1.6137312650680542\n",
      "epoch:903, loss:1.6299610137939453\n",
      "epoch:904, loss:1.6327273845672607\n",
      "epoch:905, loss:1.6072155237197876\n",
      "epoch:906, loss:1.6266604661941528\n",
      "epoch:907, loss:1.6285278797149658\n",
      "epoch:908, loss:1.631090521812439\n",
      "epoch:909, loss:1.6228357553482056\n",
      "epoch:910, loss:1.6322835683822632\n",
      "epoch:911, loss:1.6153637170791626\n",
      "epoch:912, loss:1.6327635049819946\n",
      "epoch:913, loss:1.6136776208877563\n",
      "epoch:914, loss:1.6177983283996582\n",
      "epoch:915, loss:1.6225366592407227\n",
      "epoch:916, loss:1.6291782855987549\n",
      "epoch:917, loss:1.625246286392212\n",
      "epoch:918, loss:1.6343812942504883\n",
      "epoch:919, loss:1.618039608001709\n",
      "epoch:920, loss:1.618217945098877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:921, loss:1.599098563194275\n",
      "epoch:922, loss:1.6179600954055786\n",
      "epoch:923, loss:1.6292725801467896\n",
      "epoch:924, loss:1.617895483970642\n",
      "epoch:925, loss:1.6168514490127563\n",
      "epoch:926, loss:1.6375905275344849\n",
      "epoch:927, loss:1.6056386232376099\n",
      "epoch:928, loss:1.6253979206085205\n",
      "epoch:929, loss:1.6227692365646362\n",
      "epoch:930, loss:1.6192387342453003\n",
      "epoch:931, loss:1.6145200729370117\n",
      "epoch:932, loss:1.6150225400924683\n",
      "epoch:933, loss:1.6153740882873535\n",
      "epoch:934, loss:1.610262155532837\n",
      "epoch:935, loss:1.6103109121322632\n",
      "epoch:936, loss:1.5992449522018433\n",
      "epoch:937, loss:1.6370819807052612\n",
      "epoch:938, loss:1.621054768562317\n",
      "epoch:939, loss:1.6164116859436035\n",
      "epoch:940, loss:1.6120046377182007\n",
      "epoch:941, loss:1.6180449724197388\n",
      "epoch:942, loss:1.620736002922058\n",
      "epoch:943, loss:1.6142830848693848\n",
      "epoch:944, loss:1.6359518766403198\n",
      "epoch:945, loss:1.618153691291809\n",
      "epoch:946, loss:1.6257476806640625\n",
      "epoch:947, loss:1.6139194965362549\n",
      "epoch:948, loss:1.6142641305923462\n",
      "epoch:949, loss:1.623146653175354\n",
      "epoch:950, loss:1.6179790496826172\n",
      "Training data Accuracy : 453698/1091672 = 0.416\n",
      "epoch:951, loss:1.6352577209472656\n",
      "epoch:952, loss:1.6300618648529053\n",
      "epoch:953, loss:1.6240535974502563\n",
      "epoch:954, loss:1.6193338632583618\n",
      "epoch:955, loss:1.6214351654052734\n",
      "epoch:956, loss:1.6193203926086426\n",
      "epoch:957, loss:1.6213840246200562\n",
      "epoch:958, loss:1.62013578414917\n",
      "epoch:959, loss:1.6259713172912598\n",
      "epoch:960, loss:1.6190049648284912\n",
      "epoch:961, loss:1.62418794631958\n",
      "epoch:962, loss:1.6249271631240845\n",
      "epoch:963, loss:1.619632601737976\n",
      "epoch:964, loss:1.6191527843475342\n",
      "epoch:965, loss:1.6211423873901367\n",
      "epoch:966, loss:1.6086583137512207\n",
      "epoch:967, loss:1.617309808731079\n",
      "epoch:968, loss:1.6177788972854614\n",
      "epoch:969, loss:1.6294524669647217\n",
      "epoch:970, loss:1.627195954322815\n",
      "epoch:971, loss:1.620665192604065\n",
      "epoch:972, loss:1.610251545906067\n",
      "epoch:973, loss:1.620803952217102\n",
      "epoch:974, loss:1.6191658973693848\n",
      "epoch:975, loss:1.6163356304168701\n",
      "epoch:976, loss:1.619040846824646\n",
      "epoch:977, loss:1.6166263818740845\n",
      "epoch:978, loss:1.6194854974746704\n",
      "epoch:979, loss:1.62615966796875\n",
      "epoch:980, loss:1.6074213981628418\n",
      "epoch:981, loss:1.6074049472808838\n",
      "epoch:982, loss:1.6361725330352783\n",
      "epoch:983, loss:1.6178747415542603\n",
      "epoch:984, loss:1.6105632781982422\n",
      "epoch:985, loss:1.611952304840088\n",
      "epoch:986, loss:1.6038650274276733\n",
      "epoch:987, loss:1.6144965887069702\n",
      "epoch:988, loss:1.6231882572174072\n",
      "epoch:989, loss:1.6373497247695923\n",
      "epoch:990, loss:1.6245120763778687\n",
      "epoch:991, loss:1.6238152980804443\n",
      "epoch:992, loss:1.628916621208191\n",
      "epoch:993, loss:1.640273094177246\n",
      "epoch:994, loss:1.6285361051559448\n",
      "epoch:995, loss:1.6212353706359863\n",
      "epoch:996, loss:1.6190897226333618\n",
      "epoch:997, loss:1.618675947189331\n",
      "epoch:998, loss:1.6109037399291992\n",
      "epoch:999, loss:1.628828763961792\n",
      "epoch:1000, loss:1.6136741638183594\n",
      "Training data Accuracy : 453743/1091672 = 0.416\n",
      "epoch:1001, loss:1.6317782402038574\n",
      "epoch:1002, loss:1.6198874711990356\n",
      "epoch:1003, loss:1.6203067302703857\n",
      "epoch:1004, loss:1.6139452457427979\n",
      "epoch:1005, loss:1.612376093864441\n",
      "epoch:1006, loss:1.6203675270080566\n",
      "epoch:1007, loss:1.6240259408950806\n",
      "epoch:1008, loss:1.6201963424682617\n",
      "epoch:1009, loss:1.6258676052093506\n",
      "epoch:1010, loss:1.6160916090011597\n",
      "epoch:1011, loss:1.610909104347229\n",
      "epoch:1012, loss:1.6274126768112183\n",
      "epoch:1013, loss:1.6389977931976318\n",
      "epoch:1014, loss:1.6200209856033325\n",
      "epoch:1015, loss:1.6161110401153564\n",
      "epoch:1016, loss:1.6206327676773071\n",
      "epoch:1017, loss:1.6111705303192139\n",
      "epoch:1018, loss:1.6201950311660767\n",
      "epoch:1019, loss:1.62783944606781\n",
      "epoch:1020, loss:1.6271581649780273\n",
      "epoch:1021, loss:1.6090764999389648\n",
      "epoch:1022, loss:1.6154415607452393\n",
      "epoch:1023, loss:1.6138641834259033\n",
      "epoch:1024, loss:1.6228002309799194\n",
      "epoch:1025, loss:1.612833857536316\n",
      "epoch:1026, loss:1.6314455270767212\n",
      "epoch:1027, loss:1.6235744953155518\n",
      "epoch:1028, loss:1.6200648546218872\n",
      "epoch:1029, loss:1.6338238716125488\n",
      "epoch:1030, loss:1.6114425659179688\n",
      "epoch:1031, loss:1.614439845085144\n",
      "epoch:1032, loss:1.617197036743164\n",
      "epoch:1033, loss:1.6209499835968018\n",
      "epoch:1034, loss:1.6179240942001343\n",
      "epoch:1035, loss:1.6189587116241455\n",
      "epoch:1036, loss:1.6234008073806763\n",
      "epoch:1037, loss:1.6259284019470215\n",
      "epoch:1038, loss:1.6359806060791016\n",
      "epoch:1039, loss:1.6198642253875732\n",
      "epoch:1040, loss:1.6034040451049805\n",
      "epoch:1041, loss:1.6171443462371826\n",
      "epoch:1042, loss:1.6147236824035645\n",
      "epoch:1043, loss:1.6183675527572632\n",
      "epoch:1044, loss:1.6335504055023193\n",
      "epoch:1045, loss:1.6152539253234863\n",
      "epoch:1046, loss:1.6232140064239502\n",
      "epoch:1047, loss:1.6324639320373535\n",
      "epoch:1048, loss:1.6137356758117676\n",
      "epoch:1049, loss:1.606780767440796\n",
      "epoch:1050, loss:1.6202043294906616\n",
      "Training data Accuracy : 454216/1091672 = 0.416\n",
      "epoch:1051, loss:1.6188658475875854\n",
      "epoch:1052, loss:1.6180425882339478\n",
      "epoch:1053, loss:1.6278843879699707\n",
      "epoch:1054, loss:1.6171146631240845\n",
      "epoch:1055, loss:1.6227591037750244\n",
      "epoch:1056, loss:1.6129177808761597\n",
      "epoch:1057, loss:1.6231586933135986\n",
      "epoch:1058, loss:1.6147245168685913\n",
      "epoch:1059, loss:1.6052806377410889\n",
      "epoch:1060, loss:1.6168737411499023\n",
      "epoch:1061, loss:1.6168065071105957\n",
      "epoch:1062, loss:1.616667628288269\n",
      "epoch:1063, loss:1.610921025276184\n",
      "epoch:1064, loss:1.6179211139678955\n",
      "epoch:1065, loss:1.6160098314285278\n",
      "epoch:1066, loss:1.620866060256958\n",
      "epoch:1067, loss:1.6179029941558838\n",
      "epoch:1068, loss:1.6214871406555176\n",
      "epoch:1069, loss:1.6203107833862305\n",
      "epoch:1070, loss:1.6156376600265503\n",
      "epoch:1071, loss:1.616642951965332\n",
      "epoch:1072, loss:1.619592547416687\n",
      "epoch:1073, loss:1.603968620300293\n",
      "epoch:1074, loss:1.618201732635498\n",
      "epoch:1075, loss:1.6246517896652222\n",
      "epoch:1076, loss:1.613202452659607\n",
      "epoch:1077, loss:1.6191463470458984\n",
      "epoch:1078, loss:1.6152467727661133\n",
      "epoch:1079, loss:1.6129475831985474\n",
      "epoch:1080, loss:1.6143258810043335\n",
      "epoch:1081, loss:1.6206285953521729\n",
      "epoch:1082, loss:1.626209020614624\n",
      "epoch:1083, loss:1.620121717453003\n",
      "epoch:1084, loss:1.622429370880127\n",
      "epoch:1085, loss:1.6107476949691772\n",
      "epoch:1086, loss:1.6160998344421387\n",
      "epoch:1087, loss:1.6077244281768799\n",
      "epoch:1088, loss:1.6216716766357422\n",
      "epoch:1089, loss:1.609952688217163\n",
      "epoch:1090, loss:1.62100350856781\n",
      "epoch:1091, loss:1.6141575574874878\n",
      "epoch:1092, loss:1.6341990232467651\n",
      "epoch:1093, loss:1.613154411315918\n",
      "epoch:1094, loss:1.6295109987258911\n",
      "epoch:1095, loss:1.6132091283798218\n",
      "epoch:1096, loss:1.6141996383666992\n",
      "epoch:1097, loss:1.6284257173538208\n",
      "epoch:1098, loss:1.621564507484436\n",
      "epoch:1099, loss:1.6169850826263428\n",
      "epoch:1100, loss:1.6192917823791504\n",
      "Training data Accuracy : 455797/1091672 = 0.418\n",
      "epoch:1101, loss:1.6013476848602295\n",
      "epoch:1102, loss:1.613885521888733\n",
      "epoch:1103, loss:1.6181753873825073\n",
      "epoch:1104, loss:1.6077876091003418\n",
      "epoch:1105, loss:1.6073318719863892\n",
      "epoch:1106, loss:1.6197539567947388\n",
      "epoch:1107, loss:1.6100656986236572\n",
      "epoch:1108, loss:1.6169623136520386\n",
      "epoch:1109, loss:1.6226534843444824\n",
      "epoch:1110, loss:1.6134603023529053\n",
      "epoch:1111, loss:1.6186610460281372\n",
      "epoch:1112, loss:1.6268876791000366\n",
      "epoch:1113, loss:1.6137893199920654\n",
      "epoch:1114, loss:1.616379976272583\n",
      "epoch:1115, loss:1.619622826576233\n",
      "epoch:1116, loss:1.6263718605041504\n",
      "epoch:1117, loss:1.61007559299469\n",
      "epoch:1118, loss:1.6133968830108643\n",
      "epoch:1119, loss:1.6116644144058228\n",
      "epoch:1120, loss:1.6320581436157227\n",
      "epoch:1121, loss:1.6194756031036377\n",
      "epoch:1122, loss:1.5940343141555786\n",
      "epoch:1123, loss:1.6206655502319336\n",
      "epoch:1124, loss:1.6106842756271362\n",
      "epoch:1125, loss:1.6277199983596802\n",
      "epoch:1126, loss:1.6118985414505005\n",
      "epoch:1127, loss:1.6270716190338135\n",
      "epoch:1128, loss:1.6175129413604736\n",
      "epoch:1129, loss:1.632256269454956\n",
      "epoch:1130, loss:1.6181391477584839\n",
      "epoch:1131, loss:1.616404414176941\n",
      "epoch:1132, loss:1.6083803176879883\n",
      "epoch:1133, loss:1.6118727922439575\n",
      "epoch:1134, loss:1.6150752305984497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-413cc4c1e739>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    857\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;31m# request that overlapped reads stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "for epoch in range(epochs):\n",
    "    for X,y in train_loader:\n",
    "        X = X.float().to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X.view(-1, 1 * input_len))\n",
    "        #loss = nn.CrossEntropyLoss()(pred, y)\n",
    "        loss = F.nll_loss(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'epoch:{epoch}, loss:{loss}')\n",
    "    LOSS.append(loss)\n",
    "    \n",
    "    if epoch%check == 0:\n",
    "        model.eval()\n",
    "        corr = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X,y in train_loader:\n",
    "                X = X.float().to(device)\n",
    "                y = y.to(device)\n",
    "                out = model(X.view(-1,input_len))\n",
    "                corr += (torch.argmax(out,dim=1) == y.squeeze()).sum().item()\n",
    "                total += y.size(0)\n",
    "        acc = round(corr/total,3)\n",
    "        Precision.append(acc)\n",
    "        path = f\"D:/DataMining/HW2_kaggle/model_log_FFT/{epoch}-model-parameters.pt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        if acc > acc_best:\n",
    "            acc_best = acc\n",
    "            torch.save(model.state_dict(), \"D:/DataMining/HW2_kaggle/model_log_FFT/best-model-parameters.pt\")\n",
    "        print(f'Training data Accuracy : {corr}/{total} = {round(corr/total, 3)}')\n",
    "        model.train()\n",
    "    plot_loss(check,epoch,loss.cpu().detach().numpy(),acc)\n",
    "    \n",
    "model.eval()\n",
    "\n",
    "corr = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X,y in train_loader:\n",
    "        X = X.float().to(device)\n",
    "        y = y.to(device)\n",
    "        out = model(X.view(-1,input_len))\n",
    "        corr += (torch.argmax(out,dim=1) == y.squeeze()).sum().item()\n",
    "        total += y.size(0)\n",
    "        \n",
    "acc = round(corr/total,3)\n",
    "Precision.append(acc)\n",
    "if acc > acc_best:\n",
    "    acc_best = acc\n",
    "    torch.save(model.state_dict(), \"D:/DataMining/HW2_kaggle/model_log_FFT/best-model-parameters.pt\")\n",
    "            \n",
    "print(f'Training data Accuracy : {corr}/{total} = {round(corr/total, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data Accuracy : 138206/363891 = 0.38\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "corr = 0\n",
    "total = 0\n",
    "pred = []\n",
    "true = []\n",
    "with torch.no_grad():\n",
    "    for X,y in tset_loader:\n",
    "        X = X.float().to(device)\n",
    "        y = y.to(device)\n",
    "        out = model(X.view(-1,input_len))\n",
    "        corr += (torch.argmax(out,dim=1) == y.long().squeeze()).sum().item()\n",
    "        total += y.size(0)\n",
    "        Pre = torch.argmax(out,dim=1).cpu().numpy()\n",
    "        pred.append(Pre)\n",
    "        true.append(y.long().squeeze().cpu().numpy())\n",
    "print(f'Testing data Accuracy : {corr}/{total} = {round(corr/total, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for sublist in pred:\n",
    "    for item in sublist:\n",
    "        y_pred.append(item)\n",
    "y_True = []\n",
    "for sublist in true:\n",
    "    for item in sublist:\n",
    "        y_True.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 5040x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=y_True, y_pred=y_pred)\n",
    "\n",
    "%matplotlib inline\n",
    "my_tags = pd.unique(df_label.emotion)\n",
    "plot_confusion_matrix(cm, classes=my_tags, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'joy' 'joy' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'joy' 'joy' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'joy' 'joy' ... 'joy' 'anticipation' 'joy']\n",
      "['sadness' 'joy' 'sadness' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'joy' 'joy' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'joy' 'joy' ... 'joy' 'sadness' 'joy']\n",
      "['joy' 'joy' 'joy' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'anticipation' 'joy' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'joy' 'joy' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'joy' 'joy' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'joy' 'joy' ... 'joy' 'joy' 'anticipation']\n",
      "['anticipation' 'joy' 'joy' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'anticipation' 'joy' ... 'joy' 'joy' 'joy']\n",
      "['joy' 'joy' 'anticipation' ... 'joy' 'sadness' 'joy']\n",
      "['joy' 'joy' 'joy' ... 'joy' 'anticipation' 'sadness']\n",
      "['joy' 'joy' 'anticipation' ... 'joy' 'joy' 'joy']\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for X,y in val_loader:\n",
    "        X = X.float().to(device)\n",
    "        #y = y.to(device)\n",
    "        out = model(X.view(-1,input_len))\n",
    "        Pre = torch.argmax(out,dim=1).cpu().numpy()\n",
    "        prediction.append(le.inverse_transform(Pre))\n",
    "        print(prediction[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list = []\n",
    "for sublist in prediction:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "flat_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out = pd.DataFrame({\"id\":df_data_test.tweet_id,\"emotion\":flat_list})\n",
    "Out.set_index(\"id\" , inplace=True)\n",
    "Out.to_csv('D:/DataMining/HW2_kaggle/ResultFinal.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
